# â¤ï¸ Heart Disease Prediction using Machine Learning

Heart disease remains one of the leading causes of death worldwide, making early detection and prevention essential.  
This project leverages **machine learning** to predict the likelihood of heart disease in patients using key health parameters.

By applying and comparing multiple classification algorithms, we identify the most accurate model for prediction â€” helping improve diagnosis, guide treatment, and promote healthier lives.

---

## ğŸ“Œ Project Highlights

- **Objective:** Predict the presence of heart disease (**binary classification**) using patient health metrics.
- **Dataset:** Heart disease patient data containing multiple health-related features and a binary target variable (presence/absence of heart disease).
- **Best Accuracy Achieved:** **87%** using **Logistic Regression**.

---

## ğŸ›  Machine Learning Models Implemented

- Logistic Regression *(Scikit-learn)*
- Naive Bayes *(Scikit-learn)*
- Support Vector Machine (Linear Kernel) *(Scikit-learn)*
- K-Nearest Neighbours *(Scikit-learn)*
- Decision Tree *(Scikit-learn)*

---

## ğŸ—‚ Tools & Libraries

- **Programming Language:** Python  
- **Environment:** Jupyter Notebook  
- **Libraries:**
  - [Scikit-learn](https://scikit-learn.org/) â€“ Machine learning algorithms
  - [Pandas](https://pandas.pydata.org/) â€“ Data manipulation
  - [NumPy](https://numpy.org/) â€“ Numerical computing
  - [Matplotlib](https://matplotlib.org/) & [Seaborn](https://seaborn.pydata.org/) â€“ Data visualization

---

## ğŸ“Š Workflow

1. **Data Preprocessing** â€“ Cleaning, handling missing values, feature scaling.  
2. **Exploratory Data Analysis (EDA)** â€“ Understanding patterns and relationships in the dataset.  
3. **Model Training & Comparison** â€“ Implementing multiple ML algorithms.  
4. **Evaluation** â€“ Accuracy comparison and performance metrics.  
5. **Model Selection** â€“ Logistic Regression chosen for best performance.  

---

## Conclusion: 
Logistic Regression delivered the highest accuracy and was selected as the final model.
Other models performed slightly lower but still demonstrated promising predictive capabilities.
